{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20a79f9a",
   "metadata": {},
   "source": [
    "# Code for chatbot using mongodb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c678cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "what's my name?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Your name is... UDAY! (I remember, we established that at the beginning of our conversation)\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langgraph.graph import StateGraph, MessagesState, START\n",
    "from langgraph.checkpoint.mongodb import MongoDBSaver\n",
    "\n",
    "# model = init_chat_model(model=\"anthropic:claude-3-5-haiku-latest\")\n",
    "\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "model = ChatOllama(model=\"llama3.1:8b\")\n",
    "\n",
    "\n",
    "\n",
    "DB_URI = \"localhost:27017\"\n",
    "with MongoDBSaver.from_conn_string(DB_URI) as checkpointer:\n",
    "\n",
    "    def call_model(state: MessagesState):\n",
    "        response = model.invoke(state[\"messages\"])\n",
    "        return {\"messages\": response}\n",
    "\n",
    "    builder = StateGraph(MessagesState)\n",
    "    builder.add_node(call_model)\n",
    "    builder.add_edge(START, \"call_model\")\n",
    "\n",
    "    graph = builder.compile(checkpointer=checkpointer)\n",
    "\n",
    "    config = {\n",
    "        \"configurable\": {\n",
    "            \"thread_id\": \"2\"\n",
    "        }\n",
    "    }\n",
    "\n",
    "    for chunk in graph.stream(\n",
    "        {\"messages\": [{\"role\": \"user\", \"content\": \"hi! I'm uday\"}]},\n",
    "        config,\n",
    "        stream_mode=\"values\"\n",
    "    ):\n",
    "        chunk[\"messages\"][-1].pretty_print()\n",
    "\n",
    "    for chunk in graph.stream(\n",
    "        {\"messages\": [{\"role\": \"user\", \"content\": \"what's my name?\"}]},\n",
    "        config,\n",
    "        stream_mode=\"values\"\n",
    "    ):\n",
    "        chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3dd8fb9",
   "metadata": {},
   "source": [
    "# JD Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5b81693",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain.prompts'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdotenv\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_dotenv\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprompts\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PromptTemplate\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_openai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AzureChatOpenAI\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Load environment variables\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'langchain.prompts'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize Azure OpenAI GPT-4\n",
    "model = AzureChatOpenAI(\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\"),\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    deployment_name=os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\"),\n",
    "    temperature=0.3\n",
    ")\n",
    "\n",
    "template = \"\"\"\n",
    "You are an expert HR copywriter with experience in the tech industry. Your task is to write a clear, engaging, and comprehensive job description based on the provided keywords.\n",
    "\n",
    "**Job Title:** {job_title}\n",
    "\n",
    "**Company Tone:** {company_tone}\n",
    "\n",
    "**Key Responsibilities:**\n",
    "{responsibilities}\n",
    "\n",
    "**Core Skills Required:**\n",
    "{skills}\n",
    "\n",
    "**Years of Experience:** {experience} years\n",
    "\n",
    "Based on the information above, please generate a full job description. The description must include the following sections in Markdown format:\n",
    "- ## About the Role\n",
    "- ## Key Responsibilities\n",
    "- ## Required Qualifications\n",
    "- ## Preferred Qualifications (You can infer these based on the role)\n",
    "- ## Why You'll Love Working With Us\n",
    "\n",
    "Ensure the language and tone match the specified company tone. Do not invent benefits or company details unless they are general and positive (e.g., \"collaborative environment\").\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"job_title\", \"company_tone\", \"responsibilities\", \"skills\", \"experience\"],\n",
    "    template=template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64602e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\udayt\\AppData\\Local\\Temp\\ipykernel_18972\\2045290583.py:3: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain = LLMChain(llm=model,prompt=prompt)\n"
     ]
    }
   ],
   "source": [
    "# Using modern LangChain syntax (no deprecation warnings)\n",
    "chain = prompt | model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8d3057",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = {\n",
    "    \"job_title\": \"Senior Backend Engineer (Python)\",\n",
    "    \"company_tone\": \"Professional yet approachable\",\n",
    "    \"responsibilities\": \"Design and build scalable APIs, database management, mentor junior engineers, lead code reviews, collaborate with frontend teams\",\n",
    "    \"skills\": \"Python, FastAPI, SQL (PostgreSQL), Docker, Kubernetes, AWS, CI/CD\",\n",
    "    \"experience\": \"5-7\"\n",
    "}\n",
    "\n",
    "print(\"üîÑ Generating Job Description with Azure OpenAI GPT-4...\")\n",
    "response = chain.invoke(user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc599a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the content from the Azure OpenAI response\n",
    "text = response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c6dc153c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Senior Backend Engineer (Python) Job Description\n",
      "### About the Role\n",
      "\n",
      "We're seeking an experienced Senior Backend Engineer to join our team, where you'll play a key role in designing and building scalable APIs that power our applications. As a seasoned engineer with 5-7 years of experience, you'll be responsible for leading code reviews, mentoring junior engineers, and collaborating closely with frontend teams to deliver high-quality software solutions.\n",
      "\n",
      "### Key Responsibilities\n",
      "\n",
      "* Design and build scalable APIs using Python and FastAPI\n",
      "* Manage databases efficiently using PostgreSQL and SQL\n",
      "* Mentor junior engineers in best practices and coding standards\n",
      "* Lead code reviews to ensure high-quality code and adherence to company guidelines\n",
      "* Collaborate closely with frontend teams to deliver seamless user experiences\n",
      "* Ensure smooth deployment and scaling of applications using Docker, Kubernetes, and AWS\n",
      "\n",
      "### Required Qualifications\n",
      "\n",
      "* 5-7 years of experience as a Backend Engineer, preferably in Python\n",
      "* Strong expertise in Python programming language\n",
      "* Experience with FastAPI for building scalable APIs\n",
      "* Proficiency in SQL (PostgreSQL) for database management\n",
      "* Familiarity with containerization using Docker and orchestration using Kubernetes\n",
      "* Knowledge of AWS services for cloud deployment\n",
      "* Experience with CI/CD pipelines for automated testing and deployment\n",
      "\n",
      "### Preferred Qualifications\n",
      "\n",
      "* Bachelor's or Master's degree in Computer Science, Engineering, or related fields\n",
      "* Experience with microservices architecture and distributed systems\n",
      "* Familiarity with DevOps practices and tools (e.g., Jenkins, Git)\n",
      "* Knowledge of security best practices and compliance regulations (e.g., GDPR, HIPAA)\n",
      "\n",
      "### Why You'll Love Working With Us\n",
      "\n",
      "Our company is built on a foundation of collaboration, innovation, and a passion for delivering high-quality software solutions. As a Senior Backend Engineer, you'll be part of a team that values open communication, continuous learning, and mutual respect. We offer a dynamic work environment where your skills and expertise will be challenged and valued. If you're passionate about building scalable APIs, mentoring junior engineers, and collaborating with cross-functional teams, we'd love to hear from you!\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ca7be2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fpdf import FPDF\n",
    "\n",
    "def save_text_to_pdf(markdown_text, filename=\"Job.pdf\"):\n",
    "    \"\"\"\n",
    "    Parses markdown-like text and saves it as a PDF file.\n",
    "    Handles titles (##), bullet points (-), and paragraphs.\n",
    "    \"\"\"\n",
    "    pdf = FPDF()\n",
    "    pdf.add_page()\n",
    "    pdf.set_auto_page_break(auto=True, margin=15)\n",
    "    \n",
    "    # Use a common font that supports a range of characters\n",
    "    pdf.set_font(\"Arial\", size=12)\n",
    "\n",
    "    lines = markdown_text.split('\\n')\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if line.startswith('### '):\n",
    "            # H2 Title\n",
    "            pdf.set_font(\"Arial\", 'B', 16)\n",
    "            # Remove the '## ' prefix before writing\n",
    "            pdf.multi_cell(0, 10, line[3:])\n",
    "            pdf.ln(4) # Add a little space after the title\n",
    "        elif line.startswith('- '):\n",
    "            # Bullet point\n",
    "            pdf.set_font(\"Arial\", '', 12)\n",
    "            # Use multi_cell for automatic line wrapping of long bullet points\n",
    "            pdf.multi_cell(0, 6, f\"  ‚Ä¢ {line[2:]}\")\n",
    "            pdf.ln(1) # Small space between bullet points\n",
    "        elif line: # Check if line is not empty\n",
    "            # Regular paragraph\n",
    "            pdf.set_font(\"Arial\", '', 12)\n",
    "            pdf.multi_cell(0, 6, line)\n",
    "            pdf.ln(3) # Space after a paragraph\n",
    "\n",
    "    try:\n",
    "        pdf.output(filename)\n",
    "        print(f\"\\n‚úÖ Successfully saved Job Description as '{filename}'\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error saving PDF: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c6afc119",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_text_to_pdf(markdown_text, filename=\"job_description.pdf\"):\n",
    "    \"\"\"\n",
    "    Parses markdown-like text and saves it as a PDF file using fpdf2.\n",
    "    Handles a main title (##), subtitles (###), bullet points (*), and paragraphs.\n",
    "    \"\"\"\n",
    "    pdf = FPDF()\n",
    "    pdf.add_page()\n",
    "    pdf.set_auto_page_break(auto=True, margin=15)\n",
    "    \n",
    "    # Use a standard, universally available font like Arial.\n",
    "    pdf.set_font(\"Arial\", size=12)\n",
    "\n",
    "    lines = markdown_text.split('\\n')\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if line.startswith('## '):\n",
    "            # H2 Main Title\n",
    "            pdf.set_font(\"Arial\", 'B', 20)\n",
    "            pdf.multi_cell(0, 12, line[3:], align='C') # Centered title\n",
    "            pdf.ln(10) \n",
    "        elif line.startswith('### '):\n",
    "            # H3 Subtitle\n",
    "            pdf.set_font(\"Arial\", 'B', 16)\n",
    "            pdf.multi_cell(0, 10, line[4:])\n",
    "            pdf.ln(4)\n",
    "        elif line.startswith('* '):\n",
    "            # Bullet point\n",
    "            pdf.set_font(\"Arial\", '', 12)\n",
    "            # Use a simple ASCII character for the bullet to avoid encoding errors.\n",
    "            pdf.multi_cell(0, 6, f\"  - {line[2:]}\")\n",
    "            pdf.ln(1) # Small space between bullet points\n",
    "        elif line: # Check if line is not empty\n",
    "            # Regular paragraph\n",
    "            pdf.set_font(\"Arial\", '', 12)\n",
    "            pdf.multi_cell(0, 6, line)\n",
    "            pdf.ln(3) # Space after a paragraph\n",
    "\n",
    "    try:\n",
    "        pdf.output(filename)\n",
    "        print(f\"\\n‚úÖ Successfully saved Job Description as '{filename}'\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error saving PDF: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fb2cf254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Successfully saved Job Description as 'job_description.pdf'\n"
     ]
    }
   ],
   "source": [
    "save_text_to_pdf(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d1c208",
   "metadata": {},
   "source": [
    "# Resume screener & candidate matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4476b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Dict, Literal\n",
    "\n",
    "# --- 1. Pydantic Models for Structured Data ---\n",
    "# These models define the exact structure of the data we want to extract and generate.\n",
    "\n",
    "class JobDescription(BaseModel):\n",
    "    \"\"\"Structured data extracted from a job description.\"\"\"\n",
    "    required_skills: List[str] = Field(description=\"A list of essential skills required for the job.\")\n",
    "    preferred_skills: List[str] = Field(description=\"A list of preferred but not mandatory skills.\")\n",
    "    years_of_experience: int = Field(description=\"The minimum number of years of experience required.\")\n",
    "\n",
    "class CandidateResume(BaseModel):\n",
    "    \"\"\"Structured data extracted from a candidate's resume.\"\"\"\n",
    "    name: str = Field(description=\"The full name of the candidate.\")\n",
    "    skills: List[str] = Field(description=\"A list of skills possessed by the candidate.\")\n",
    "    work_experience: List[Dict] = Field(description=\"A list of previous work experiences, including job title, company, and duration in years.\")\n",
    "    total_experience_years: int = Field(description=\"The total number of years of professional experience.\")\n",
    "\n",
    "class ScreeningResult(BaseModel):\n",
    "    \"\"\"The final output of the screening process.\"\"\"\n",
    "    match_score: int = Field(description=\"A score from 0 to 100 representing the candidate's suitability.\", ge=0, le=100)\n",
    "    summary: str = Field(description=\"A concise summary explaining the reasoning behind the score, highlighting strengths and weaknesses.\")\n",
    "    status: Literal[\"Strong Match\", \"Potential Fit\", \"Not a Fit\"] = Field(description=\"The final recommendation status.\")\n",
    "\n",
    "\n",
    "# --- 2. The AI Core Logic ---\n",
    "\n",
    "class ResumeScreenerAI:\n",
    "    def __init__(self, model_name=\"llama3.1:8b\"):\n",
    "        \"\"\"Initializes the AI Screener with the specified Ollama model.\"\"\"\n",
    "        try:\n",
    "            self.llm = Ollama(model=model_name, temperature=0.0, format=\"json\")\n",
    "            print(f\"‚úÖ LLM model '{model_name}' initialized successfully.\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error initializing Ollama model: {e}\")\n",
    "            raise\n",
    "\n",
    "    def _extract_structured_data(self, text: str, pydantic_model):\n",
    "        \"\"\"A generic function to extract structured data from text using a Pydantic model.\"\"\"\n",
    "        parser = PydanticOutputParser(pydantic_object=pydantic_model)\n",
    "        \n",
    "        prompt = PromptTemplate(\n",
    "            template=\"You are an expert HR data analyst. Extract the relevant information from the document below and format it according to the provided JSON schema.\\n{format_instructions}\\nDocument:\\n{document_text}\",\n",
    "            input_variables=[\"document_text\"],\n",
    "            partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    "        )\n",
    "        \n",
    "        chain = LLMChain(llm=self.llm, prompt=prompt)\n",
    "        \n",
    "        try:\n",
    "            output = chain.invoke({\"document_text\": text})\n",
    "            parsed_output = parser.parse(output['text'])\n",
    "            return parsed_output\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error during data extraction: {e}\")\n",
    "            return None\n",
    "\n",
    "    def screen_resume(self, jd_text: str, resume_text: str):\n",
    "        \"\"\"\n",
    "        Performs the two-step screening process: extraction and comparison.\n",
    "        \"\"\"\n",
    "        print(\"\\n--- Step 1: Extracting structured data from documents ---\")\n",
    "        \n",
    "        # Extract data from Job Description\n",
    "        jd_data = self._extract_structured_data(jd_text, JobDescription)\n",
    "        if not jd_data:\n",
    "            print(\"‚ùå Failed to process Job Description.\")\n",
    "            return None\n",
    "        print(\"‚úÖ Job Description data extracted:\")\n",
    "        print(jd_data.model_dump_json(indent=2))\n",
    "\n",
    "        # Extract data from Resume\n",
    "        resume_data = self._extract_structured_data(resume_text, CandidateResume)\n",
    "        if not resume_data:\n",
    "            print(\"‚ùå Failed to process Resume.\")\n",
    "            return None\n",
    "        print(\"\\n‚úÖ Resume data extracted:\")\n",
    "        print(resume_data.model_dump_json(indent=2))\n",
    "\n",
    "        print(\"\\n--- Step 2: Comparing data and generating screening result ---\")\n",
    "        \n",
    "        comparison_parser = PydanticOutputParser(pydantic_object=ScreeningResult)\n",
    "\n",
    "        comparison_prompt = PromptTemplate(\n",
    "            template=\"\"\"\n",
    "            You are an expert Senior Technical Recruiter with 15 years of experience.\n",
    "            Analyze the candidate's resume against the job description based on the structured data provided.\n",
    "            Provide a match score, a concise summary of your analysis, and a final status.\n",
    "            \n",
    "            Job Requirements:\n",
    "            {jd_json}\n",
    "            \n",
    "            Candidate's Resume:\n",
    "            {resume_json}\n",
    "            \n",
    "            {format_instructions}\n",
    "            \"\"\",\n",
    "            input_variables=[\"jd_json\", \"resume_json\"],\n",
    "            partial_variables={\"format_instructions\": comparison_parser.get_format_instructions()},\n",
    "        )\n",
    "        \n",
    "        comparison_chain = LLMChain(llm=self.llm, prompt=comparison_prompt)\n",
    "        \n",
    "        try:\n",
    "            result_output = comparison_chain.invoke({\n",
    "                \"jd_json\": jd_data.model_dump_json(),\n",
    "                \"resume_json\": resume_data.model_dump_json()\n",
    "            })\n",
    "            final_result = comparison_parser.parse(result_output['text'])\n",
    "            return final_result\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error during comparison: {e}\")\n",
    "            return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "534869b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Initializing AI Resume Screener ---\n",
      "‚úÖ LLM model 'llama3.1:8b' initialized successfully.\n",
      "\n",
      "--- Step 1: Extracting structured data from documents ---\n",
      "‚úÖ Job Description data extracted:\n",
      "{\n",
      "  \"required_skills\": [\n",
      "    \"Python\",\n",
      "    \"FastAPI\",\n",
      "    \"PostgreSQL\"\n",
      "  ],\n",
      "  \"preferred_skills\": [\n",
      "    \"Docker\",\n",
      "    \"AWS\"\n",
      "  ],\n",
      "  \"years_of_experience\": 5\n",
      "}\n",
      "\n",
      "‚úÖ Resume data extracted:\n",
      "{\n",
      "  \"name\": \"John Doe\",\n",
      "  \"skills\": [\n",
      "    \"Python, Django, Flask, FastAPI\",\n",
      "    \"PostgreSQL, MySQL, Redis\",\n",
      "    \"Docker, Kubernetes, Jenkins\",\n",
      "    \"Git, JIRA\"\n",
      "  ],\n",
      "  \"work_experience\": [\n",
      "    {\n",
      "      \"job_title\": \"Senior Software Engineer\",\n",
      "      \"company\": \"Tech Solutions Inc.\",\n",
      "      \"duration_years\": 3\n",
      "    },\n",
      "    {\n",
      "      \"job_title\": \"Software Engineer\",\n",
      "      \"company\": \"Data Corp.\",\n",
      "      \"duration_years\": 3\n",
      "    }\n",
      "  ],\n",
      "  \"total_experience_years\": 6\n",
      "}\n",
      "\n",
      "--- Step 2: Comparing data and generating screening result ---\n",
      "\n",
      "\n",
      "--- üöÄ Final Screening Result ---\n",
      "---------------------------------\n",
      "{\n",
      "  \"match_score\": 80,\n",
      "  \"summary\": \"The candidate has strong skills in Python and FastAPI, but lacks experience with Docker and AWS. Their total experience is 6 years, which meets the requirement of at least 5 years. However, their work experience is split between two roles, which might indicate a lack of depth in one area.\",\n",
      "  \"status\": \"Potential Fit\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "SAMPLE_JOB_DESCRIPTION = \"\"\"\n",
    "Job Title: Senior Python Developer\n",
    "\n",
    "We are looking for a Senior Python Developer with at least 5 years of experience.\n",
    "The ideal candidate must be proficient in Python, FastAPI, and PostgreSQL.\n",
    "Experience with Docker and AWS is highly preferred. Key responsibilities include\n",
    "developing backend services and mentoring junior engineers.\n",
    "\"\"\"\n",
    "\n",
    "SAMPLE_RESUME = \"\"\"\n",
    "Name: John Doe\n",
    "Email: john.doe@email.com\n",
    "\n",
    "Summary:\n",
    "A skilled software engineer with 6 years of experience in backend development.\n",
    "\n",
    "Skills:\n",
    "- Python, Django, Flask, FastAPI\n",
    "- PostgreSQL, MySQL, Redis\n",
    "- Docker, Kubernetes, Jenkins\n",
    "- Git, JIRA\n",
    "\n",
    "Work Experience:\n",
    "- Senior Software Engineer at Tech Solutions Inc. (3 years)\n",
    "    - Led a team to build a microservices architecture using FastAPI and Docker.\n",
    "- Software Engineer at Data Corp. (3 years)\n",
    "    - Developed and maintained APIs using Python and Django.\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Initializing AI Resume Screener ---\")\n",
    "\n",
    "try:\n",
    "    screener = ResumeScreenerAI()\n",
    "    \n",
    "    final_screening = screener.screen_resume(\n",
    "        jd_text=SAMPLE_JOB_DESCRIPTION,\n",
    "        resume_text=SAMPLE_RESUME\n",
    "    )\n",
    "    \n",
    "    if final_screening:\n",
    "        print(\"\\n\\n--- üöÄ Final Screening Result ---\")\n",
    "        print(\"---------------------------------\")\n",
    "        print(final_screening.model_dump_json(indent=2))\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"\\nAn unexpected error occurred during the main execution: {e}\")\n",
    "    print(\"Please ensure Ollama is running and accessible.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4975d246",
   "metadata": {},
   "source": [
    "# AI-Powered Initiat Screening Interviewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4a9e3419",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Dict, TypedDict, Optional, Literal\n",
    "\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# --- 1. Define the State for our Graph ---\n",
    "# This TypedDict will be the \"memory\" of our interview agent.\n",
    "\n",
    "class InterviewState(TypedDict):\n",
    "    job_description: str\n",
    "    interview_plan: Optional[List[str]]\n",
    "    conversation_history: List[Dict[str, str]]\n",
    "    evaluations: List[Dict]\n",
    "    current_question: Optional[str]\n",
    "    final_summary: Optional[str]\n",
    "    max_questions: int\n",
    "\n",
    "# --- 2. Define Pydantic Models for Structured Output ---\n",
    "\n",
    "class InterviewPlan(BaseModel):\n",
    "    topics: List[str] = Field(description=\"A list of 3-5 key technical and behavioral topics to cover in an interview.\")\n",
    "\n",
    "class Question(BaseModel):\n",
    "    question: str = Field(description=\"The next question to ask the candidate.\")\n",
    "\n",
    "class Evaluation(BaseModel):\n",
    "    rating: int = Field(description=\"A rating of the candidate's answer from 1 (poor) to 5 (excellent).\")\n",
    "    feedback: str = Field(description=\"A brief justification for the rating, explaining what was good or could be improved.\")\n",
    "\n",
    "class Summary(BaseModel):\n",
    "    recommendation: Literal[\"Proceed\", \"Hold\", \"Reject\"] = Field(description=\"The final hiring recommendation.\")\n",
    "    summary_text: str = Field(description=\"A comprehensive summary of the candidate's performance during the interview.\")\n",
    "\n",
    "\n",
    "# --- 3. The AI Core Logic (Nodes of the Graph) ---\n",
    "\n",
    "class InterviewerAI:\n",
    "    def __init__(self):\n",
    "        # Initialize the Azure Chat OpenAI model\n",
    "        try:\n",
    "            self.llm = AzureChatOpenAI(\n",
    "                api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "                api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\"),\n",
    "                azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "                deployment_name=os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\"),\n",
    "                temperature=0.1,\n",
    "                model_kwargs={\n",
    "                    \"response_format\": {\"type\": \"json_object\"},\n",
    "                }\n",
    "            )\n",
    "            print(\"‚úÖ Azure OpenAI model initialized successfully.\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Failed to initialize Azure OpenAI model. Please check your .env file and credentials.\")\n",
    "            print(f\"Error: {e}\")\n",
    "            raise\n",
    "\n",
    "    def generate_interview_plan(self, state: InterviewState):\n",
    "        print(\"--- Node: Generating Interview Plan ---\")\n",
    "        jd = state['job_description']\n",
    "        parser = PydanticOutputParser(pydantic_object=InterviewPlan)\n",
    "\n",
    "        template = \"\"\"\n",
    "        You are a senior hiring manager. Read the job description and generate a list of 5 key topics to discuss.\n",
    "\n",
    "        You MUST format your output as a JSON object with a single key \"topics\".\n",
    "\n",
    "        Example Format:\n",
    "        {{\n",
    "          \"topics\": [\"Python fundamentals\", \"FastAPI experience\", \"Database knowledge\", \"Team collaboration\", \"Problem-solving skills\"]\n",
    "        }}\n",
    "\n",
    "        Job Description:\n",
    "        {jd}\n",
    "        \"\"\"\n",
    "        prompt = PromptTemplate(template=template, input_variables=[\"jd\"])\n",
    "        chain = prompt | self.llm | parser\n",
    "        plan = chain.invoke({\"jd\": jd})\n",
    "        return {\"interview_plan\": plan.topics}\n",
    "\n",
    "    def generate_question(self, state: InterviewState):\n",
    "        print(\"--- Node: Generating Question ---\")\n",
    "        history = state['conversation_history']\n",
    "        plan = state['interview_plan']\n",
    "        evals = state['evaluations']\n",
    "        \n",
    "        instruction = \"You are an expert interviewer. \"\n",
    "        if evals and evals[-1]['rating'] < 3:\n",
    "             instruction += f\"The candidate's previous answer was weak. Ask a follow-up question to probe deeper into the topic of: '{history[-1]['question']}'.\"\n",
    "        else:\n",
    "            next_topic = plan[len(evals)] if len(evals) < len(plan) else \"a final concluding question\"\n",
    "            instruction += f\"Based on the interview plan, ask the next question about the topic: '{next_topic}'.\"\n",
    "            \n",
    "        parser = PydanticOutputParser(pydantic_object=Question)\n",
    "        template = \"\"\"\n",
    "        {instruction}\n",
    "\n",
    "        You MUST format your output as a JSON object with a single key \"question\".\n",
    "\n",
    "        Example Format:\n",
    "        {{\n",
    "            \"question\": \"Can you describe a challenging project you worked on using FastAPI?\"\n",
    "        }}\n",
    "\n",
    "        Conversation History:\n",
    "        {history}\n",
    "        \"\"\"\n",
    "        prompt = PromptTemplate(template=template, input_variables=[\"instruction\", \"history\"])\n",
    "        chain = prompt | self.llm | parser\n",
    "        question_obj = chain.invoke({\"instruction\": instruction, \"history\": history})\n",
    "        return {\"current_question\": question_obj.question}\n",
    "\n",
    "    def evaluate_answer(self, state: InterviewState):\n",
    "        print(\"--- Node: Evaluating Answer ---\")\n",
    "        question = state['current_question']\n",
    "        \n",
    "        candidate_answer = input(f\"ü§ñ AI: {question}\\nüë§ You: \")\n",
    "\n",
    "        history = state['conversation_history']\n",
    "        history.append({\"question\": question, \"answer\": candidate_answer})\n",
    "        \n",
    "        parser = PydanticOutputParser(pydantic_object=Evaluation)\n",
    "        template = \"\"\"\n",
    "        You are an expert interview evaluator. Evaluate the candidate's answer based on the question asked.\n",
    "\n",
    "        You MUST format your output as a JSON object with the keys \"rating\" and \"feedback\".\n",
    "\n",
    "        Example Format:\n",
    "        {{\n",
    "            \"rating\": 4,\n",
    "            \"feedback\": \"The candidate provided a solid, real-world example and clearly explained the technical challenges.\"\n",
    "        }}\n",
    "\n",
    "        Question:\n",
    "        {question}\n",
    "        \n",
    "        Candidate's Answer:\n",
    "        {answer}\n",
    "        \"\"\"\n",
    "        prompt = PromptTemplate(template=template, input_variables=[\"question\", \"answer\"])\n",
    "        chain = prompt | self.llm | parser\n",
    "        evaluation = chain.invoke({\"question\": question, \"answer\": candidate_answer})\n",
    "\n",
    "        evals = state['evaluations']\n",
    "        evals.append(evaluation.model_dump())\n",
    "        \n",
    "        return {\"conversation_history\": history, \"evaluations\": evals}\n",
    "\n",
    "    def summarize_interview(self, state: InterviewState):\n",
    "        print(\"--- Node: Summarizing Interview ---\")\n",
    "        history = state['conversation_history']\n",
    "        evals = state['evaluations']\n",
    "        \n",
    "        parser = PydanticOutputParser(pydantic_object=Summary)\n",
    "        template = \"\"\"\n",
    "        You are a senior hiring manager. Based on the entire interview, write a final summary and provide a hiring recommendation.\n",
    "\n",
    "        You MUST format your output as a JSON object with the keys \"recommendation\" and \"summary_text\".\n",
    "        The \"recommendation\" value MUST be one of the following exact strings: \"Proceed\", \"Hold\", or \"Reject\".\n",
    "\n",
    "        Example Format:\n",
    "        {{\n",
    "            \"recommendation\": \"Proceed\",\n",
    "            \"summary_text\": \"The candidate demonstrated strong technical skills in Python and FastAPI. They communicated effectively and showed good problem-solving abilities. Recommend proceeding to the next round.\"\n",
    "        }}\n",
    "\n",
    "        Interview Transcript:\n",
    "        {history}\n",
    "\n",
    "        Evaluations:\n",
    "        {evals}\n",
    "        \"\"\"\n",
    "        prompt = PromptTemplate(template=template, input_variables=[\"history\", \"evals\"])\n",
    "        chain = prompt | self.llm | parser\n",
    "        summary = chain.invoke({\"history\": history, \"evals\": evals})\n",
    "        return {\"final_summary\": summary.model_dump_json(indent=2)}\n",
    "\n",
    "# --- 4. The Routing Logic (Edges) ---\n",
    "\n",
    "def route_after_evaluation(state: InterviewState):\n",
    "    print(\"--- Edge: Routing after evaluation ---\")\n",
    "    evals = state['evaluations']\n",
    "    if len(evals) >= state['max_questions']:\n",
    "        print(\"Decision: End of interview. Moving to summarize.\")\n",
    "        return \"summarize\"\n",
    "    else:\n",
    "        print(\"Decision: Continue interview. Moving to generate next question.\")\n",
    "        return \"generate_question\"\n",
    "\n",
    "# --- 5. Build and Run the Graph ---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bc34bc6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Azure OpenAI model initialized successfully.\n",
      "\n",
      "--- Starting AI Interview ---\n",
      "--- Node: Generating Interview Plan ---\n",
      "\n",
      "Output from node 'generate_plan':\n",
      "---\n",
      "--- Node: Generating Question ---\n",
      "\n",
      "Output from node 'generate_question':\n",
      "---\n",
      "--- Node: Evaluating Answer ---\n",
      "--- Edge: Routing after evaluation ---\n",
      "Decision: Continue interview. Moving to generate next question.\n",
      "\n",
      "Output from node 'evaluate_answer':\n",
      "---\n",
      "--- Node: Generating Question ---\n",
      "\n",
      "Output from node 'generate_question':\n",
      "---\n",
      "--- Node: Evaluating Answer ---\n",
      "--- Edge: Routing after evaluation ---\n",
      "Decision: Continue interview. Moving to generate next question.\n",
      "\n",
      "Output from node 'evaluate_answer':\n",
      "---\n",
      "--- Node: Generating Question ---\n",
      "\n",
      "Output from node 'generate_question':\n",
      "---\n",
      "--- Node: Evaluating Answer ---\n",
      "--- Edge: Routing after evaluation ---\n",
      "Decision: Continue interview. Moving to generate next question.\n",
      "\n",
      "Output from node 'evaluate_answer':\n",
      "---\n",
      "--- Node: Generating Question ---\n",
      "\n",
      "Output from node 'generate_question':\n",
      "---\n",
      "--- Node: Evaluating Answer ---\n",
      "--- Edge: Routing after evaluation ---\n",
      "Decision: End of interview. Moving to summarize.\n",
      "\n",
      "Output from node 'evaluate_answer':\n",
      "---\n",
      "--- Node: Summarizing Interview ---\n",
      "\n",
      "Output from node 'summarize':\n",
      "---\n",
      "\n",
      "\n",
      "--- üöÄ Final Interview Summary ---\n",
      "---------------------------------\n",
      "{\n",
      "  \"recommendation\": \"Reject\",\n",
      "  \"summary_text\": \"The candidate struggled to provide detailed responses regarding their experience with Python and pandas. They mentioned pandas but failed to elaborate on its features or provide specific examples of its application in their projects. The lack of detail and incomplete answers indicate insufficient knowledge and experience, leading to a recommendation to reject the candidate.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    SAMPLE_JOB_DESCRIPTION = \"\"\"\n",
    "    Job Title: Senior Python Developer\n",
    "    We are looking for a Senior Python Developer with at least 5 years of experience.\n",
    "    The ideal candidate must be proficient in Python, FastAPI, and PostgreSQL.\n",
    "    Experience with Docker and AWS is highly preferred. Key responsibilities include\n",
    "    developing backend services and mentoring junior engineers. The role requires strong\n",
    "    problem-solving skills and excellent team collaboration.\n",
    "    \"\"\"\n",
    "    \n",
    "    ai_interviewer = InterviewerAI()\n",
    "\n",
    "    # Define the graph\n",
    "    workflow = StateGraph(InterviewState)\n",
    "\n",
    "    # Add the nodes\n",
    "    workflow.add_node(\"generate_plan\", ai_interviewer.generate_interview_plan)\n",
    "    workflow.add_node(\"generate_question\", ai_interviewer.generate_question)\n",
    "    workflow.add_node(\"evaluate_answer\", ai_interviewer.evaluate_answer)\n",
    "    workflow.add_node(\"summarize\", ai_interviewer.summarize_interview)\n",
    "\n",
    "    # Set the entry point\n",
    "    workflow.set_entry_point(\"generate_plan\")\n",
    "\n",
    "    # Add the edges\n",
    "    workflow.add_edge(\"generate_plan\", \"generate_question\")\n",
    "    workflow.add_edge(\"generate_question\", \"evaluate_answer\")\n",
    "    workflow.add_conditional_edges(\n",
    "        \"evaluate_answer\",\n",
    "        route_after_evaluation,\n",
    "        {\n",
    "            \"summarize\": \"summarize\",\n",
    "            \"generate_question\": \"generate_question\"\n",
    "        }\n",
    "    )\n",
    "    workflow.add_edge(\"summarize\", END)\n",
    "\n",
    "    # Compile the graph\n",
    "    app = workflow.compile()\n",
    "\n",
    "    # Run the interview\n",
    "    print(\"\\n--- Starting AI Interview ---\")\n",
    "    initial_state = {\n",
    "        \"job_description\": SAMPLE_JOB_DESCRIPTION,\n",
    "        \"conversation_history\": [],\n",
    "        \"evaluations\": [],\n",
    "        \"max_questions\": 4 # Let's do a 4-question interview\n",
    "    }\n",
    "\n",
    "    # Use stream to see the output of each step\n",
    "    final_state_value = None\n",
    "    for output in app.stream(initial_state):\n",
    "        # The key is the name of the node that just ran\n",
    "        for key, value in output.items():\n",
    "            print(f\"\\nOutput from node '{key}':\")\n",
    "            print(\"---\")\n",
    "            final_state_value = value # Continuously update to get the last valid state\n",
    "\n",
    "    # Access the final summary from the last known state\n",
    "    if final_state_value:\n",
    "        final_summary = final_state_value.get('final_summary')\n",
    "        print(\"\\n\\n--- üöÄ Final Interview Summary ---\")\n",
    "        print(\"---------------------------------\")\n",
    "        print(final_summary)\n",
    "    else:\n",
    "        print(\"\\n--- Interview could not be completed. ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1254e65b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- üß™ Starting Full Azure Voice Environment Test ---\n",
      "\n",
      "--- üé§ Testing Whisper (Speech-to-Text) ---\n",
      "‚úîÔ∏è All Whisper variables found.\n",
      "... Contacting Whisper deployment...\n",
      "‚ùå FAILED: Could not connect to Whisper service. Error: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}\n",
      "\n",
      "--- üó£Ô∏è Testing Speech Services (Text-to-Speech) ---\n",
      "‚úîÔ∏è All Speech Service variables found.\n",
      "‚ùå FAILED: Could not connect to Speech service. Error: default speaker needs to be explicitly activated\n",
      "\n",
      "--- üìä Test Summary ---\n",
      "üö´ One or more tests failed. Please review the errors above and check your .env file.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# A single script to test both Whisper and Speech Service credentials.\n",
    "\n",
    "def test_whisper_config():\n",
    "    \"\"\"Tests the Azure Whisper (Speech-to-Text) configuration.\"\"\"\n",
    "    print(\"\\n--- üé§ Testing Whisper (Speech-to-Text) ---\")\n",
    "    \n",
    "    # 1. Check for necessary environment variables\n",
    "    required_vars = [\n",
    "        \"AZURE_OPENAI_API_KEY\",\n",
    "        \"AZURE_OPENAI_ENDPOINT\",\n",
    "        \"AZURE_OPENAI_API_VERSION\",\n",
    "        \"AZURE_OPENAI_WHISPER_DEPLOYMENT_NAME\"\n",
    "    ]\n",
    "    if not all(os.getenv(var) for var in required_vars):\n",
    "        print(\"‚ùå FAILED: Missing one or more Azure OpenAI environment variables for Whisper.\")\n",
    "        return False\n",
    "    \n",
    "    print(\"‚úîÔ∏è All Whisper variables found.\")\n",
    "    \n",
    "    # 2. Attempt to make an API call\n",
    "    try:\n",
    "        from openai import AzureOpenAI\n",
    "        import io, wave\n",
    "\n",
    "        client = AzureOpenAI(\n",
    "            api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "            api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\"),\n",
    "            azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "        )\n",
    "        \n",
    "        # Create a dummy silent WAV file in memory to send for transcription\n",
    "        audio_buffer = io.BytesIO()\n",
    "        with wave.open(audio_buffer, 'wb') as wf:\n",
    "            wf.setnchannels(1); wf.setsampwidth(2); wf.setframerate(16000)\n",
    "            wf.writeframes(b'\\x00' * 1600) # 0.1 seconds of silence\n",
    "        audio_buffer.seek(0)\n",
    "        audio_buffer.name = \"test.wav\"\n",
    "        \n",
    "        print(\"... Contacting Whisper deployment...\")\n",
    "        client.audio.transcriptions.create(\n",
    "            model=os.getenv(\"AZURE_OPENAI_WHISPER_DEPLOYMENT_NAME\"),\n",
    "            file=audio_buffer\n",
    "        )\n",
    "        print(\"‚úÖ SUCCESS: Whisper configuration is correct.\")\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå FAILED: Could not connect to Whisper service. Error: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def test_speech_services_config():\n",
    "    \"\"\"Tests the Azure Speech Services (Text-to-Speech) configuration.\"\"\"\n",
    "    print(\"\\n--- üó£Ô∏è Testing Speech Services (Text-to-Speech) ---\")\n",
    "\n",
    "    # 1. Check for necessary environment variables\n",
    "    required_vars = [\"AZURE_SPEECH_KEY\", \"AZURE_SPEECH_REGION\"]\n",
    "    if not all(os.getenv(var) for var in required_vars):\n",
    "        print(\"‚ùå FAILED: Missing AZURE_SPEECH_KEY or AZURE_SPEECH_REGION.\")\n",
    "        return False\n",
    "\n",
    "    print(\"‚úîÔ∏è All Speech Service variables found.\")\n",
    "\n",
    "    # 2. Attempt to make an API call\n",
    "    try:\n",
    "        import azure.cognitiveservices.speech as speechsdk\n",
    "        \n",
    "        speech_key = os.getenv(\"AZURE_SPEECH_KEY\")\n",
    "        speech_region = os.getenv(\"AZURE_SPEECH_REGION\")\n",
    "        \n",
    "        speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=speech_region)\n",
    "        \n",
    "        # We don't need to actually play the audio, just confirm the API call works.\n",
    "        # So, we use a null audio output configuration.\n",
    "        audio_config = speechsdk.audio.AudioOutputConfig(use_default_speaker=False)\n",
    "\n",
    "        synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=audio_config)\n",
    "\n",
    "        print(\"... Contacting Speech service...\")\n",
    "        result = synthesizer.speak_text_async(\"This is a test.\").get()\n",
    "        \n",
    "        if result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:\n",
    "            print(\"‚úÖ SUCCESS: Speech Services configuration is correct.\")\n",
    "            return True\n",
    "        else:\n",
    "            cancellation_details = result.cancellation_details\n",
    "            print(f\"‚ùå FAILED: Speech synthesis canceled: {cancellation_details.reason}\")\n",
    "            if cancellation_details.reason == speechsdk.CancellationReason.Error:\n",
    "                print(f\"   Error details: {cancellation_details.error_details}\")\n",
    "            return False\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå FAILED: Could not connect to Speech service. Error: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"--- üß™ Starting Full Azure Voice Environment Test ---\")\n",
    "    load_dotenv()\n",
    "    \n",
    "    whisper_ok = test_whisper_config()\n",
    "    speech_ok = test_speech_services_config()\n",
    "    \n",
    "    print(\"\\n--- üìä Test Summary ---\")\n",
    "    if whisper_ok and speech_ok:\n",
    "        print(\"üéâ All configurations are correct! Your application should work.\")\n",
    "    else:\n",
    "        print(\"üö´ One or more tests failed. Please review the errors above and check your .env file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6faa8dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "endpoint = \"https://mazenetai23-7805-resource.cognitiveservices.azure.com/\"\n",
    "model_name = \"gpt-4o-mini\"\n",
    "deployment = \"gpt-4o-mini\"\n",
    "\n",
    "subscription_key = \"<your-api-key>\"\n",
    "api_version = \"2024-12-01-preview\"\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_version=api_version,\n",
    "    azure_endpoint=endpoint,\n",
    "    api_key=subscription_key,\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"I am going to Paris, what should I see?\",\n",
    "        }\n",
    "    ],\n",
    "    max_tokens=4096,\n",
    "    temperature=1.0,\n",
    "    top_p=1.0,\n",
    "    model=deployment\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b884713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "  üß™ TalentFlow AI - Azure OpenAI Configuration Test Suite\n",
      "======================================================================\n",
      "\n",
      "\n",
      "======================================================================\n",
      "  üîç Checking Environment Variables\n",
      "======================================================================\n",
      "  ‚úÖ AZURE_OPENAI_API_KEY: DriisREt...W5PG\n",
      "  ‚úÖ AZURE_OPENAI_ENDPOINT: https://mazenetai27-9892-resource.openai.azure.com/\n",
      "  ‚úÖ AZURE_OPENAI_API_VERSION: 2024-12-01-preview\n",
      "  ‚úÖ AZURE_OPENAI_CHAT_DEPLOYMENT_NAME: gpt-4o-mini\n",
      "\n",
      "‚úÖ All environment variables are configured!\n",
      "\n",
      "üì° Initializing Azure OpenAI client...\n",
      "‚úÖ Client initialized successfully!\n",
      "\n",
      "======================================================================\n",
      "  üåê Test 1: Basic Connection\n",
      "======================================================================\n",
      "Deployment: gpt-4o-mini\n",
      "Testing connection with a simple prompt...\n",
      "\n",
      "‚ùå Connection failed!\n",
      "Error: Error code: 401 - {'error': {'code': '401', 'message': 'Access denied due to invalid subscription key or wrong API endpoint. Make sure to provide a valid key for an active subscription and use a correct regional API endpoint for your resource.'}}\n",
      "\n",
      "======================================================================\n",
      "  üìù Test 2: Job Description Generation\n",
      "======================================================================\n",
      "Testing JD generation with sample data...\n",
      "\n",
      "‚ùå JD Generation failed!\n",
      "Error: Error code: 401 - {'error': {'code': '401', 'message': 'Access denied due to invalid subscription key or wrong API endpoint. Make sure to provide a valid key for an active subscription and use a correct regional API endpoint for your resource.'}}\n",
      "\n",
      "======================================================================\n",
      "  üé§ Test 3: AI Interview (JSON Mode)\n",
      "======================================================================\n",
      "Testing interview question generation with JSON mode...\n",
      "\n",
      "‚ùå AI Interview (JSON mode) failed!\n",
      "Error: Error code: 401 - {'error': {'code': '401', 'message': 'Access denied due to invalid subscription key or wrong API endpoint. Make sure to provide a valid key for an active subscription and use a correct regional API endpoint for your resource.'}}\n",
      "\n",
      "======================================================================\n",
      "  ‚ö° Test 4: Rate Limits & Performance\n",
      "======================================================================\n",
      "Sending 3 rapid requests to test rate limits...\n",
      "\n",
      "‚ùå Rate limit test failed!\n",
      "Error: Error code: 401 - {'error': {'code': '401', 'message': 'Access denied due to invalid subscription key or wrong API endpoint. Make sure to provide a valid key for an active subscription and use a correct regional API endpoint for your resource.'}}\n",
      "\n",
      "======================================================================\n",
      "  üí∞ Test 5: Token Usage & Cost Estimation\n",
      "======================================================================\n",
      "Testing token usage tracking...\n",
      "\n",
      "‚ùå Token usage test failed!\n",
      "Error: Error code: 401 - {'error': {'code': '401', 'message': 'Access denied due to invalid subscription key or wrong API endpoint. Make sure to provide a valid key for an active subscription and use a correct regional API endpoint for your resource.'}}\n",
      "\n",
      "======================================================================\n",
      "  üìä Test Summary\n",
      "======================================================================\n",
      "  ‚ùå FAIL - Basic Connection\n",
      "  ‚ùå FAIL - JD Generation\n",
      "  ‚ùå FAIL - AI Interview (JSON)\n",
      "  ‚ùå FAIL - Rate Limits\n",
      "  ‚ùå FAIL - Token Usage\n",
      "\n",
      "  Results: 0/5 tests passed\n",
      "\n",
      "  ‚ö†Ô∏è  Some tests failed. Please review the errors above.\n",
      "  üí° Common issues:\n",
      "     - Wrong deployment name\n",
      "     - Invalid API key\n",
      "     - Quota exceeded\n",
      "     - Wrong API version\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "TalentFlow AI - Complete Azure OpenAI Configuration Test\n",
    "Test all API keys and endpoints used in the application\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "import time\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Configuration check\n",
    "def check_env_vars():\n",
    "    \"\"\"Check if all required environment variables are set\"\"\"\n",
    "    print(\"=\"*70)\n",
    "    print(\"  üîç Checking Environment Variables\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    required_vars = {\n",
    "        \"AZURE_OPENAI_API_KEY\": \"API Key for Azure OpenAI\",\n",
    "        \"AZURE_OPENAI_ENDPOINT\": \"Endpoint URL\",\n",
    "        \"AZURE_OPENAI_API_VERSION\": \"API Version\",\n",
    "        \"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\": \"Chat Model Deployment (GPT-4)\"\n",
    "    }\n",
    "    \n",
    "    missing = []\n",
    "    for var, desc in required_vars.items():\n",
    "        value = os.getenv(var)\n",
    "        if not value or value.startswith(\"your_\"):\n",
    "            print(f\"  ‚ùå {var}: NOT CONFIGURED\")\n",
    "            print(f\"     Description: {desc}\")\n",
    "            missing.append(var)\n",
    "        else:\n",
    "            # Mask sensitive data\n",
    "            if \"KEY\" in var:\n",
    "                masked = value[:8] + \"...\" + value[-4:] if len(value) > 12 else \"***\"\n",
    "                print(f\"  ‚úÖ {var}: {masked}\")\n",
    "            else:\n",
    "                print(f\"  ‚úÖ {var}: {value}\")\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    if missing:\n",
    "        print(f\"‚ö†Ô∏è  Missing variables: {', '.join(missing)}\")\n",
    "        return False\n",
    "    else:\n",
    "        print(\"‚úÖ All environment variables are configured!\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "# Initialize Azure OpenAI client\n",
    "def init_client():\n",
    "    \"\"\"Initialize Azure OpenAI client\"\"\"\n",
    "    try:\n",
    "        client = AzureOpenAI(\n",
    "            api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "            api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\"),\n",
    "            azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "        )\n",
    "        return client\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to initialize client: {e}\")\n",
    "        return None\n",
    "\n",
    "# Test 1: Basic Connection Test\n",
    "def test_connection(client):\n",
    "    \"\"\"Test basic connection to Azure OpenAI\"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"  üåê Test 1: Basic Connection\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    try:\n",
    "        deployment = os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\")\n",
    "        \n",
    "        print(f\"Deployment: {deployment}\")\n",
    "        print(\"Testing connection with a simple prompt...\")\n",
    "        \n",
    "        response = client.chat.completions.create(\n",
    "            model=deployment,\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": \"Say 'Hello TalentFlow AI!' if you can hear me.\"}\n",
    "            ],\n",
    "            max_tokens=50,\n",
    "            temperature=0\n",
    "        )\n",
    "        \n",
    "        result = response.choices[0].message.content\n",
    "        print(f\"\\n‚úÖ Connection successful!\")\n",
    "        print(f\"Response: {result}\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Connection failed!\")\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "# Test 2: JD Generator Endpoint Test\n",
    "def test_jd_generation(client):\n",
    "    \"\"\"Test JD generation functionality\"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"  üìù Test 2: Job Description Generation\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    try:\n",
    "        deployment = os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\")\n",
    "        \n",
    "        template = \"\"\"You are an expert HR copywriter. Generate a brief job description for:\n",
    "Job Title: Software Engineer\n",
    "Required Skills: Python, FastAPI\n",
    "Experience: 3 years\n",
    "\n",
    "Provide a 2-sentence job description.\"\"\"\n",
    "\n",
    "        print(\"Testing JD generation with sample data...\")\n",
    "        \n",
    "        response = client.chat.completions.create(\n",
    "            model=deployment,\n",
    "            messages=[{\"role\": \"user\", \"content\": template}],\n",
    "            max_tokens=200,\n",
    "            temperature=0.3\n",
    "        )\n",
    "        \n",
    "        result = response.choices[0].message.content\n",
    "        print(f\"\\n‚úÖ JD Generation successful!\")\n",
    "        print(f\"Generated JD preview:\\n{result[:150]}...\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå JD Generation failed!\")\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "# Test 3: AI Interview Endpoint Test (JSON Mode)\n",
    "def test_interview_json_mode(client):\n",
    "    \"\"\"Test AI interview with JSON output\"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"  üé§ Test 3: AI Interview (JSON Mode)\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    try:\n",
    "        deployment = os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\")\n",
    "        \n",
    "        prompt = \"\"\"You are an AI interviewer. Generate a technical interview question.\n",
    "You MUST format your output as a JSON object with a single key \"question\".\n",
    "\n",
    "Example Format:\n",
    "{\n",
    "    \"question\": \"Can you explain the difference between async and sync programming?\"\n",
    "}\"\"\"\n",
    "\n",
    "        print(\"Testing interview question generation with JSON mode...\")\n",
    "        \n",
    "        response = client.chat.completions.create(\n",
    "            model=deployment,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            max_tokens=200,\n",
    "            temperature=0.1,\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "        \n",
    "        result = response.choices[0].message.content\n",
    "        print(f\"\\n‚úÖ AI Interview (JSON mode) successful!\")\n",
    "        print(f\"JSON Response:\\n{result}\")\n",
    "        \n",
    "        # Verify it's valid JSON\n",
    "        import json\n",
    "        parsed = json.loads(result)\n",
    "        print(f\"‚úÖ Valid JSON - Question extracted: {parsed.get('question', 'N/A')[:80]}...\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå AI Interview (JSON mode) failed!\")\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "# Test 4: Rate Limit and Quota Check\n",
    "def test_rate_limits(client):\n",
    "    \"\"\"Test rate limits with multiple requests\"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"  ‚ö° Test 4: Rate Limits & Performance\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    try:\n",
    "        deployment = os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\")\n",
    "        \n",
    "        print(\"Sending 3 rapid requests to test rate limits...\")\n",
    "        \n",
    "        for i in range(3):\n",
    "            start = time.time()\n",
    "            response = client.chat.completions.create(\n",
    "                model=deployment,\n",
    "                messages=[{\"role\": \"user\", \"content\": f\"Count to {i+1}\"}],\n",
    "                max_tokens=20\n",
    "            )\n",
    "            elapsed = time.time() - start\n",
    "            print(f\"  Request {i+1}: ‚úÖ Success ({elapsed:.2f}s)\")\n",
    "            time.sleep(0.5)  # Small delay between requests\n",
    "        \n",
    "        print(\"\\n‚úÖ Rate limit test passed! No throttling detected.\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Rate limit test failed!\")\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        if \"429\" in str(e):\n",
    "            print(\"‚ÑπÔ∏è  This is a rate limit error. Your quota may be exceeded.\")\n",
    "        return False\n",
    "\n",
    "# Test 5: Token Usage and Cost Estimation\n",
    "def test_token_usage(client):\n",
    "    \"\"\"Test token usage reporting\"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"  üí∞ Test 5: Token Usage & Cost Estimation\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    try:\n",
    "        deployment = os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\")\n",
    "        \n",
    "        prompt = \"Explain what TalentFlow AI does in one sentence.\"\n",
    "        \n",
    "        print(\"Testing token usage tracking...\")\n",
    "        \n",
    "        response = client.chat.completions.create(\n",
    "            model=deployment,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            max_tokens=100\n",
    "        )\n",
    "        \n",
    "        usage = response.usage\n",
    "        print(f\"\\n‚úÖ Token usage tracked successfully!\")\n",
    "        print(f\"  Prompt tokens: {usage.prompt_tokens}\")\n",
    "        print(f\"  Completion tokens: {usage.completion_tokens}\")\n",
    "        print(f\"  Total tokens: {usage.total_tokens}\")\n",
    "        \n",
    "        # Rough cost estimation (GPT-4 pricing example)\n",
    "        prompt_cost = (usage.prompt_tokens / 1000) * 0.03  # $0.03 per 1K prompt tokens\n",
    "        completion_cost = (usage.completion_tokens / 1000) * 0.06  # $0.06 per 1K completion tokens\n",
    "        total_cost = prompt_cost + completion_cost\n",
    "        \n",
    "        print(f\"\\n  üíµ Estimated cost: ${total_cost:.6f}\")\n",
    "        print(f\"     (Based on GPT-4 pricing: $0.03/1K prompt, $0.06/1K completion)\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Token usage test failed!\")\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "# Run all tests\n",
    "def run_all_tests():\n",
    "    \"\"\"Run all Azure OpenAI configuration tests\"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"  üß™ TalentFlow AI - Azure OpenAI Configuration Test Suite\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    # Check environment variables\n",
    "    if not check_env_vars():\n",
    "        print(\"\\n‚ùå Cannot proceed with tests. Please configure your .env file.\")\n",
    "        return\n",
    "    \n",
    "    # Initialize client\n",
    "    print(\"\\nüì° Initializing Azure OpenAI client...\")\n",
    "    client = init_client()\n",
    "    \n",
    "    if not client:\n",
    "        print(\"\\n‚ùå Cannot proceed with tests. Client initialization failed.\")\n",
    "        return\n",
    "    \n",
    "    print(\"‚úÖ Client initialized successfully!\")\n",
    "    \n",
    "    # Run tests\n",
    "    results = {\n",
    "        \"Basic Connection\": test_connection(client),\n",
    "        \"JD Generation\": test_jd_generation(client),\n",
    "        \"AI Interview (JSON)\": test_interview_json_mode(client),\n",
    "        \"Rate Limits\": test_rate_limits(client),\n",
    "        \"Token Usage\": test_token_usage(client)\n",
    "    }\n",
    "    \n",
    "    # Summary\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"  üìä Test Summary\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    passed = sum(1 for v in results.values() if v)\n",
    "    total = len(results)\n",
    "    \n",
    "    for test_name, result in results.items():\n",
    "        status = \"‚úÖ PASS\" if result else \"‚ùå FAIL\"\n",
    "        print(f\"  {status} - {test_name}\")\n",
    "    \n",
    "    print(f\"\\n  Results: {passed}/{total} tests passed\")\n",
    "    \n",
    "    if passed == total:\n",
    "        print(\"\\n  üéâ All tests passed! Your Azure OpenAI is configured correctly!\")\n",
    "        print(\"  üöÄ TalentFlow AI is ready to use!\")\n",
    "    else:\n",
    "        print(\"\\n  ‚ö†Ô∏è  Some tests failed. Please review the errors above.\")\n",
    "        print(\"  üí° Common issues:\")\n",
    "        print(\"     - Wrong deployment name\")\n",
    "        print(\"     - Invalid API key\")\n",
    "        print(\"     - Quota exceeded\")\n",
    "        print(\"     - Wrong API version\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Execute the test suite\n",
    "if __name__ == \"__main__\":\n",
    "    run_all_tests()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef243ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the Azure OpenAI configuration test suite\n",
    "run_all_tests()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f24c95c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa03c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paris is a beautiful city with a rich history, stunning architecture, and vibrant culture. Here are some must-see attractions and activities to consider during your visit:\n",
      "\n",
      "1. **Eiffel Tower**: A trip to Paris isn't complete without visiting the iconic Eiffel Tower. You can go to the top for fantastic views of the city or enjoy a picnic in the nearby Champ de Mars.\n",
      "\n",
      "2. **Louvre Museum**: As one of the largest and most famous art museums in the world, the Louvre is home to masterpieces like the Mona Lisa and the Venus de Milo.\n",
      "\n",
      "3. **Notre-Dame Cathedral**: Although it suffered damage in the 2019 fire, Notre-Dame remains a symbol of Paris. You can admire its exterior and explore the √éle de la Cit√©.\n",
      "\n",
      "4. **Montmartre and the Basilica of Sacr√©-C≈ìur**: Wander through the charming streets of Montmartre, visit the Basilica of Sacr√©-C≈ìur for panoramic views of the city, and enjoy the artistic atmosphere.\n",
      "\n",
      "5. **Champs-√âlys√©es and Arc de Triomphe**: Stroll down the famous avenue, enjoy shopping or dining, and visit the Arc de Triomphe, which honors those who fought for France.\n",
      "\n",
      "6. **Palace of Versailles**: A short trip from Paris, the opulent Palace of Versailles and its gardens are a must-see for history and architecture enthusiasts.\n",
      "\n",
      "7. **Mus√©e d'Orsay**: Located in a former railway station, this museum houses an extensive collection of Impressionist and Post-Impressionist masterpieces.\n",
      "\n",
      "8. **Seine River Cruise**: Consider a scenic boat cruise along the Seine River, especially at sunset, for stunning views of famous landmarks.\n",
      "\n",
      "9. **Saint-Germain-des-Pr√©s**: Explore this historic neighborhood known for its caf√©s, boutiques, and galleries. Don't miss the famous Caf√© de Flore and Les Deux Magots.\n",
      "\n",
      "10. **Luxembourg Gardens**: Relax in these beautiful gardens, a great spot to take a leisurely stroll or have a picnic.\n",
      "\n",
      "11. **The Latin Quarter**: Known for its lively atmosphere and intellectual history, explore the narrow streets, bookstores, and the Sorbonne University.\n",
      "\n",
      "12. **P√®re Lachaise Cemetery**: Visit the final resting place of famous figures like Jim Morrison, Oscar Wilde, and √âdith Piaf.\n",
      "\n",
      "Consider trying local cuisine, attending a show at the Moulin Rouge or a traditional cabaret, and exploring the various neighborhoods like Le Marais and Canal Saint-Martin for a taste of local life. Enjoy your trip to Paris!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "model_name = \"gpt-4o-mini\"\n",
    "deployment = \"chat-deployment\"\n",
    "\n",
    "subscription_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "api_version = \"2024-12-01-preview\"\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_version=api_version,\n",
    "    azure_endpoint=endpoint,\n",
    "    api_key=subscription_key,\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"I am going to Paris, what should I see?\",\n",
    "        }\n",
    "    ],\n",
    "    max_tokens=4096,\n",
    "    temperature=1.0,\n",
    "    top_p=1.0,\n",
    "    model=deployment\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca22d4df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uday",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
