# ===================================================================
# TalentFlow AI - Environment Variables Configuration
# ===================================================================
# 
# Copy this file to .env and fill in your actual values
# DO NOT commit .env file to version control (it's in .gitignore)
#
# ===================================================================

# ===================================================================
# AZURE OPENAI CONFIGURATION (REQUIRED)
# ===================================================================
# 
# Get these from your Azure OpenAI resource in Azure Portal
# Navigate to: Azure Portal > Your OpenAI Resource > Keys and Endpoint
#
AZURE_OPENAI_API_KEY=your_azure_openai_api_key_here
AZURE_OPENAI_ENDPOINT=https://your-resource-name.openai.azure.com/
AZURE_OPENAI_CHAT_DEPLOYMENT_NAME=gpt-4o-mini
AZURE_OPENAI_API_VERSION=2024-02-15-preview

# ===================================================================
# MONGODB CONFIGURATION
# ===================================================================
# 
# For Docker deployment, use the service name 'mongodb'
# For local development, use 'localhost'
#
# Docker (default):
MONGODB_URI=mongodb://mongodb:27017/talentflow_db
DB_NAME=talentflow_db

# Local development (uncomment if running without Docker):
# MONGODB_URI=mongodb://localhost:27017/talentflow_db
# DB_NAME=talentflow_db

# MongoDB Atlas (cloud - uncomment if using):
# MONGODB_URI=mongodb+srv://username:password@cluster.mongodb.net/talentflow_db?retryWrites=true&w=majority
# DB_NAME=talentflow_db

# ===================================================================
# DOCKER COMPUTE TYPE SELECTION
# ===================================================================
#
# Choose which compute type to use for Docker deployment
# This affects which Dockerfile and configuration is used
#
# IMPORTANT: This is only used by the startup script (start-docker.bat)
# You still need to use the correct profile when running docker compose manually
#
COMPUTE_TYPE=gpu

# Options:
# - gpu: Use NVIDIA GPU acceleration (requires NVIDIA Container Toolkit)
#   - Container size: ~10.5 GB
#   - Whisper medium model
#   - Fast transcription (~10x realtime)
#   - Requires: NVIDIA GPU with CUDA support
#
# - cpu: Use CPU-only mode (no GPU required)
#   - Container size: ~2.5 GB
#   - Whisper base model
#   - Slower transcription (~0.5x realtime)
#   - No special hardware required
#
# To switch:
# 1. Change COMPUTE_TYPE above
# 2. Run: start-docker.bat
# 3. Or manually: docker compose --profile gpu up -d
#                 docker compose --profile cpu up -d
#
# ===================================================================
# WHISPER CONFIGURATION
# ===================================================================
# 
# Configure Whisper model settings
# These can be overridden from defaults set by Docker profiles
#
WHISPER_USE_LOCAL=true

# Whisper Model Size
# GPU mode default: medium | CPU mode default: base
# Override if you want a different model size
WHISPER_MODEL_SIZE=medium

# Available models:
# - tiny: ~39 MB, fastest, lowest accuracy
# - base: ~74 MB, good for CPU mode
# - small: ~244 MB, better accuracy
# - medium: ~769 MB, recommended for GPU
# - large: ~1.5 GB, best accuracy
# - large-v2: ~1.5 GB, latest best

# Whisper Device (auto-set by Docker profile)
# GPU mode: cuda | CPU mode: cpu
WHISPER_DEVICE=cuda

# Whisper Compute Type (auto-set by Docker profile)
# GPU mode: float16 | CPU mode: int8
WHISPER_COMPUTE_TYPE=float16

# Note: 
# - Docker profiles set these automatically, but you can override them here
# - GPU mode sets: medium/cuda/float16
# - CPU mode sets: base/cpu/int8
# - Make sure the model you choose is appropriate for your compute type

# ===================================================================
# OPTIONAL CONFIGURATIONS
# ===================================================================

# Application Environment
ENV=production
DEBUG=false

# JWT Secret (generate a secure random string)
JWT_SECRET_KEY=OlDTXQlIXpqikBrkX348m5T$uqNg*dsax0JMx8*iPJ^zAhIt1GUfcuPr#v&rMp&B

# Session Configuration
SESSION_TIMEOUT_MINUTES=30

# File Upload Limits (in MB)
MAX_FILE_SIZE_MB=10

# ===================================================================
# DEVELOPMENT OVERRIDES
# ===================================================================
# 
# Uncomment these for development/testing
#
# ENV=development
# DEBUG=true
# WHISPER_MODEL_SIZE=base
# LOG_LEVEL=DEBUG

# ===================================================================
# CUDA/GPU SETTINGS (Advanced)
# ===================================================================
# 
# These are automatically set in Docker but can be customized
#
# CUDA_VISIBLE_DEVICES=0
# NVIDIA_VISIBLE_DEVICES=all
# NVIDIA_DRIVER_CAPABILITIES=compute,utility

# ===================================================================
# SETUP INSTRUCTIONS
# ===================================================================
# 
# 1. Copy this file: cp .env.example .env
# 2. Edit .env with your actual values
# 3. For Azure OpenAI:
#    - Create an Azure OpenAI resource
#    - Deploy a GPT-4o-mini model
#    - Copy the endpoint and API key
# 4. For GPU support:
#    - Ensure NVIDIA drivers are installed
#    - Install NVIDIA Container Toolkit
#    - Verify with: nvidia-smi
# 5. Start with: docker compose up -d
#
# ===================================================================
